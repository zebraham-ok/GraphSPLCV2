{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7313de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"如果不担心数据覆盖可以直接运行到底\"\n",
    "import networkx as nx\n",
    "import os\n",
    "from tqdm import  tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "output_folder=r\"result\\YearStat\"\n",
    "data_folder=r\"result\\YearOutput\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e72853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "node_set=set()\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year,_=file.split(\".\")\n",
    "    year_G=nx.read_graphml(os.path.join(data_folder, file))\n",
    "    node_set.update(year_G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "876a7ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_list=list(node_set)\n",
    "len(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c619ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# 提取绝对度\n",
    "all_data = {}\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year, _ = file.split(\".\")\n",
    "    year_G = nx.read_graphml(os.path.join(data_folder, file))\n",
    "    \n",
    "    edges_to_remove = [edge for edge in year_G.edges \n",
    "                       if year_G.edges[edge].get(\"status\", \"\") == \"Stopped\"]\n",
    "    \n",
    "    year_G.remove_edges_from(edges_to_remove)\n",
    "    \n",
    "    # 计算节点度数并存储\n",
    "    year_degree = dict(year_G.degree())\n",
    "    all_data[year] = year_degree\n",
    "    \n",
    "all_data_table=pd.DataFrame(all_data).fillna(0)\n",
    "all_data_table[\"sum\"]=all_data_table[\"2013\"]+all_data_table[\"2014\"]+all_data_table[\"2015\"]+all_data_table[\"2016\"]+all_data_table[\"2017\"]+all_data_table[\"2018\"]+all_data_table[\"2019\"]\n",
    "\n",
    "all_data_table.astype(int).sort_values(by=\"sum\", ascending=False).to_csv(os.path.join(output_folder, \"degee2013_2019.csv\"),index_label=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cb79179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 提取相对度\n",
    "all_data = {}\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year, _ = file.split(\".\")\n",
    "    year_G = nx.read_graphml(os.path.join(data_folder, file))\n",
    "    \n",
    "    edges_to_remove = [edge for edge in year_G.edges \n",
    "                       if year_G.edges[edge].get(\"status\", \"\") == \"Stopped\"]\n",
    "    \n",
    "    # 删除这些边\n",
    "    year_G.remove_edges_from(edges_to_remove)\n",
    "    \n",
    "    # 计算节点度数并存储\n",
    "    year_degree = nx.degree_centrality(year_G)\n",
    "    all_data[year] = year_degree\n",
    "    \n",
    "all_data_table=pd.DataFrame(all_data).fillna(0)\n",
    "all_data_table[\"average\"]=sum(all_data_table[i] for i in all_data_table.columns)/len(all_data_table.columns)\n",
    "\n",
    "all_data_table.sort_values(by=\"average\", ascending=False).to_csv(os.path.join(output_folder, \"degee_centrality2013_2019.csv\"),index_label=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "791e94f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# 提取临近中心度\n",
    "all_data = {}\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year, _ = file.split(\".\")\n",
    "    year_G = nx.read_graphml(os.path.join(data_folder, file))\n",
    "    \n",
    "    edges_to_remove = [edge for edge in year_G.edges \n",
    "                       if year_G.edges[edge].get(\"status\", \"\") == \"Stopped\"]\n",
    "    \n",
    "    # 删除这些边\n",
    "    year_G.remove_edges_from(edges_to_remove)\n",
    "    \n",
    "    # 计算节点度数并存储\n",
    "    year_degree = nx.closeness_centrality(year_G)\n",
    "    all_data[year] = year_degree\n",
    "    \n",
    "all_data_table=pd.DataFrame(all_data).fillna(0)\n",
    "all_data_table[\"average\"]=sum(all_data_table[i] for i in all_data_table.columns)/len(all_data_table.columns)\n",
    "\n",
    "all_data_table.sort_values(by=\"average\", ascending=False).to_csv(os.path.join(output_folder, \"closeness_centrality2013_2019.csv\"),index_label=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba10f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:16<00:00, 10.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# 提取中介中心度\n",
    "all_data = {}\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year, _ = file.split(\".\")\n",
    "    year_G = nx.read_graphml(os.path.join(data_folder, file))\n",
    "    \n",
    "    edges_to_remove = [edge for edge in year_G.edges \n",
    "                       if year_G.edges[edge].get(\"status\", \"\") == \"Stopped\"]\n",
    "    \n",
    "    # 删除这些边\n",
    "    year_G.remove_edges_from(edges_to_remove)\n",
    "    \n",
    "    # 计算节点度数并存储\n",
    "    year_degree = nx.betweenness_centrality(year_G)\n",
    "    all_data[year] = year_degree\n",
    "    \n",
    "all_data_table=pd.DataFrame(all_data).fillna(0)\n",
    "all_data_table[\"average\"]=sum(all_data_table[i] for i in all_data_table.columns)/len(all_data_table.columns)\n",
    "\n",
    "all_data_table.sort_values(by=\"average\", ascending=False).to_csv(os.path.join(output_folder, \"betweenness_centrality2013_2019.csv\"),index_label=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# 提取Pagerank\n",
    "all_data = {}\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year, _ = file.split(\".\")\n",
    "    year_G = nx.read_graphml(os.path.join(data_folder, file))\n",
    "    \n",
    "    edges_to_remove = [edge for edge in year_G.edges \n",
    "                       if year_G.edges[edge].get(\"status\", \"\") == \"Stopped\"]\n",
    "    \n",
    "    # 删除这些边\n",
    "    year_G.remove_edges_from(edges_to_remove)\n",
    "    \n",
    "    # 计算节点度数并存储\n",
    "    year_degree = nx.pagerank(year_G)\n",
    "    all_data[year] = year_degree\n",
    "    \n",
    "all_data_table=pd.DataFrame(all_data).fillna(0)\n",
    "all_data_table[\"average\"]=sum(all_data_table[i] for i in all_data_table.columns)/len(all_data_table.columns)\n",
    "\n",
    "all_data_table.sort_values(by=\"average\", ascending=False).to_csv(os.path.join(output_folder, \"pagerank2013_2019.csv\"),index_label=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d575e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
