{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7313de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"如果不担心数据覆盖可以直接运行到底\"\n",
    "import networkx as nx\n",
    "import os\n",
    "from tqdm import  tqdm\n",
    "import pandas as pd\n",
    "\n",
    "output_folder=r\"result\\YearStat\"\n",
    "data_folder=r\"result\\YearOutputOri\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e72853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:08<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "node_set=set()\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year,_=file.split(\".\")\n",
    "    year_G=nx.read_graphml(os.path.join(data_folder, file))\n",
    "    node_set.update(year_G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3d0a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '美国',\n",
       " 'industry_1st': '芯片制造设备',\n",
       " 'industry_2nd': '检测设备',\n",
       " 'category_1st': '射频芯片',\n",
       " 'category_2nd': '射频收发芯片',\n",
       " 'category_3rd': '射频收发芯片',\n",
       " 'type': 'Company',\n",
       " 'name': 'MKS仪器公司'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_G.nodes['MKS仪器公司']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876a7ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67016"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_list=list(node_set)\n",
    "data_list_of_dict={node: {} for node in node_list}  # 后续每一个节点的数据都存在这里\n",
    "len(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478f46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopped_edges(graph: nx.DiGraph, as_target=True) -> dict:\n",
    "    \"\"\"\n",
    "    计算NetworkX DiGraph中每个节点在status=\"Stopped\"的连边中作为target的次数。\n",
    "    \n",
    "    参数:\n",
    "        graph (nx.DiGraph): 输入的有向图，假设边有一个属性'status'。\n",
    "        as_target: 用来实现两个不同功能，默认True统计被断供的企业，False表示统计断供企业\n",
    "        \n",
    "    返回:\n",
    "        dict: 一个字典，键是图中的节点，值是在状态为\"Stopped\"的边中作为target的次数。\n",
    "    \"\"\"\n",
    "    # 初始化结果字典\n",
    "    count_stopped = {node: 0 for node in graph.nodes()}\n",
    "    \n",
    "    # 遍历图中的所有边\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        # 检查边是否具有'status'属性且值为'Stopped'\n",
    "        if 'status' in data and data['status'] == \"Stopped\":\n",
    "            # 增加作为target的节点v的计数\n",
    "            if as_target:\n",
    "                count_stopped[v] += 1  # 统计被断供者\n",
    "            else:\n",
    "                count_stopped[u] += 1  # 统计断供者\n",
    "            \n",
    "    # 过滤掉计数为0的项\n",
    "    # count_stopped = {k: v for k, v in count_stopped.items() if v > 0}\n",
    "    \n",
    "    return count_stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e6d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2750/2750 [00:00<00:00, 345587.73it/s]\n",
      "100%|██████████| 3061/3061 [00:00<00:00, 55379.13it/s]\n",
      "100%|██████████| 3900/3900 [00:00<00:00, 269131.06it/s]\n",
      "100%|██████████| 4988/4988 [00:00<00:00, 308004.25it/s]\n",
      "100%|██████████| 6539/6539 [00:00<00:00, 325878.11it/s]\n",
      "100%|██████████| 8265/8265 [00:00<00:00, 211731.32it/s]\n",
      "100%|██████████| 11045/11045 [00:00<00:00, 273178.09it/s]\n",
      "100%|██████████| 4205/4205 [00:00<00:00, 333857.96it/s]\n",
      "100%|██████████| 5333/5333 [00:00<00:00, 320930.63it/s]\n",
      "100%|██████████| 6291/6291 [00:00<00:00, 355697.70it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 358101.15it/s]\n",
      "100%|██████████| 12494/12494 [00:00<00:00, 284176.86it/s]\n",
      "100%|██████████| 9680/9680 [00:00<00:00, 334916.01it/s]\n",
      "100%|██████████| 13/13 [09:17<00:00, 42.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# 每次读取一个文件，这个文件中每一个公司的信息当做一行来保存\n",
    "\n",
    "all_data_list=[]\n",
    "\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    year, _ = file.split(\".\")\n",
    "    year_G = nx.read_graphml(os.path.join(data_folder, file))\n",
    "    stopped_count = count_stopped_edges(year_G, as_target=True)\n",
    "    stopper_count = count_stopped_edges(year_G, as_target=False)\n",
    "    \n",
    "    edges_to_remove = [edge for edge in year_G.edges \n",
    "                       if year_G.edges[edge].get(\"status\", \"\") == \"Stopped\"]\n",
    "    \n",
    "    # 计算节点度数并存储\n",
    "    year_degree = dict(year_G.degree())\n",
    "    year_degree_centrality = nx.degree_centrality(year_G)\n",
    "    year_closeness_centrality = nx.closeness_centrality(year_G)\n",
    "    year_between_centrality = nx.betweenness_centrality(year_G)\n",
    "    year_pagerank = nx.pagerank(year_G)\n",
    "    \n",
    "    data_map_dict={\n",
    "        \"stopped_count\": stopped_count,\n",
    "        \"stopper_count\": stopper_count,\n",
    "        \"degree\": year_degree,\n",
    "        \"degree_centrality\": year_degree_centrality,\n",
    "        \"closeness_centrality\": year_closeness_centrality,\n",
    "        \"betweenness_centrality\": year_between_centrality,\n",
    "        \"pagerank\": year_pagerank\n",
    "    }\n",
    "    \n",
    "    for node in tqdm(year_G.nodes):\n",
    "        record={\"year\": year, \"name\": node, **year_G.nodes[node]}\n",
    "        for key, value_map in data_map_dict.items():\n",
    "            record[key]=value_map[node]\n",
    "        \n",
    "        all_data_list.append(record)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a333765",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_data_list).sort_values(by=\"degree\", ascending=False).to_csv(r\"result\\YearStat\\timeSeries_with_stopped_name_reflected.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d575e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
